{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d642fbca",
   "metadata": {},
   "source": [
    "# phase 3.2 model training: LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ca6627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Masking\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464c3ac6",
   "metadata": {},
   "source": [
    "## 5-star classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757d7b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm_on_w2v_5_stars(train_text_path: str, train_labels_path: str, model_path: str) -> None:\n",
    "    # load data\n",
    "    X_train_raw = pd.read_csv(train_text_path, index_col=0)\n",
    "    y_train = pd.read_csv(train_labels_path, index_col=0).squeeze()\n",
    "\n",
    "    # align indexes\n",
    "    X_train_raw, y_train = X_train_raw.align(y_train, join='inner', axis=0)\n",
    "\n",
    "    # parse and pad W2V vectors\n",
    "    X_train_sequences = X_train_raw['text'].apply(ast.literal_eval).apply(np.array).tolist()\n",
    "    X_train_padded = pad_sequences(X_train_sequences, padding='post', dtype='float32')\n",
    "    X_train = X_train_padded\n",
    "\n",
    "    # encode labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "    y_train_categorical = to_categorical(y_train_encoded)   \n",
    "\n",
    "    # save the encoder for later decoding\n",
    "    with open(\"../models/w2v_LSTM_label_encoder.pkl\", 'wb') as file:\n",
    "        pickle.dump(label_encoder, file)\n",
    "\n",
    "    # build the LSTM model\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value=0., input_shape=input_shape))\n",
    "    model.add(LSTM(64, return_sequences=False))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(y_train_categorical.shape[1], activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # train LSTM\n",
    "    early_stopping = EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n",
    "    model.fit(X_train, y_train_categorical, epochs=10, batch_size=128, callbacks=[early_stopping])\n",
    "\n",
    "    # save LSTM to file\n",
    "    model.save(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76875e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70/30 version\n",
    "\n",
    "train_lstm_on_w2v_5_stars(\n",
    "    train_text_path='../data/70_30/train_texts_w2v.csv',\n",
    "    train_labels_path='../data/70_30/train_labels.csv',\n",
    "    model_path=\"../models/w2v_LSTM_70_30.h5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31cdb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80/20 version\n",
    "\n",
    "train_lstm_on_w2v_5_stars(\n",
    "    train_text_path='../data/80_20/train_texts_w2v.csv',\n",
    "    train_labels_path='../data/80_20/train_labels.csv',\n",
    "    model_path=\"../models/w2v_LSTM_80_20.h5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f2968b",
   "metadata": {},
   "source": [
    "## positive/neutral/negative classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8a5883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm_on_w2v_pnn(train_text_path: str, train_labels_path: str, model_path: str) -> None:\n",
    "    # load data\n",
    "    X_train_raw = pd.read_csv(train_text_path, index_col=0)\n",
    "    y_train = pd.read_csv(train_labels_path, index_col=0).squeeze()\n",
    "\n",
    "    # align indexes\n",
    "    X_train_raw, y_train = X_train_raw.align(y_train, join='inner', axis=0)\n",
    "\n",
    "    # map stars to sentiments\n",
    "    def map_sentiment(star_rating):\n",
    "        if star_rating in [4, 5]:\n",
    "            return 'Positive'\n",
    "        elif star_rating == 3:\n",
    "            return 'Neutral'\n",
    "        else:\n",
    "            return 'Negative'\n",
    "\n",
    "    y_train = y_train.map(map_sentiment)\n",
    "\n",
    "    # parse and pad W2V vectors\n",
    "    X_train_sequences = X_train_raw['text'].apply(ast.literal_eval).apply(np.array).tolist()\n",
    "    X_train_padded = pad_sequences(X_train_sequences, padding='post', dtype='float32')\n",
    "    X_train = X_train_padded\n",
    "\n",
    "    # encode labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "    y_train_categorical = to_categorical(y_train_encoded)   \n",
    "\n",
    "    # save the encoder for later decoding\n",
    "    with open(\"../models/w2v_LSTM_label_encoder_PNN.pkl\", 'wb') as file:\n",
    "        pickle.dump(label_encoder, file)\n",
    "\n",
    "    # build the LSTM model\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value=0., input_shape=input_shape))\n",
    "    model.add(LSTM(64, return_sequences=False))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(y_train_categorical.shape[1], activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # train LSTM\n",
    "    early_stopping = EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n",
    "    model.fit(X_train, y_train_categorical, epochs=10, batch_size=128, callbacks=[early_stopping])\n",
    "\n",
    "    # save LSTM to file\n",
    "    model.save(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4fc0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70/30 version\n",
    "\n",
    "train_lstm_on_w2v_pnn(\n",
    "    train_text_path='../data/70_30/train_texts_w2v.csv',\n",
    "    train_labels_path='../data/70_30/train_labels.csv',\n",
    "    model_path=\"../models/w2v_LSTM_70_30_PNN.h5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4395277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80/20 version\n",
    "\n",
    "train_lstm_on_w2v_pnn(\n",
    "    train_text_path='../data/80_20/train_texts_w2v.csv',\n",
    "    train_labels_path='../data/80_20/train_labels.csv',\n",
    "    model_path=\"../models/w2v_LSTM_80_20_PNN.h5\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
